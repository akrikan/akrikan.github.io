[
  {
    "objectID": "docu/anotherpage.html",
    "href": "docu/anotherpage.html",
    "title": "MyBlog",
    "section": "",
    "text": "Quantitative finance resources\n\n\n\n\n\n\n\nOpinion\n\n\n\n\n\n\n\n\n\n\n\nJan 2, 2023\n\n\nKrishnakant A\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "docu/about.html",
    "href": "docu/about.html",
    "title": "Krishnakant Ammanamanchi",
    "section": "",
    "text": "Hi , I am Krishnakant Ammanamanchi , welcome to my Site/Blog or whatever.\nI am unsure what to call this anymore. The gist of the site is to capture the projects and skills that i am currently working on and document them as i keep on learning as well as to write up on topics that i find fascinating.\nThere are lot sections that i have added to the site to keep myself accountable and motivated to keep posting on this site, the current goal is to populate all the sections decently enough by 2023 mid.\nFeel free to jump to any of the above sections.(Most of the sections are work in progress but eventually everything will be in order)\nHappy exploring !!!\nThis is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "docu/SEA/math.html",
    "href": "docu/SEA/math.html",
    "title": "Math",
    "section": "",
    "text": "\\alpha + \\beta\n\\Pi + \\Gamma\na \\bmod b\nx \\equiv a \\pmod{b}\n\\lim\\limits_{x \\to \\infty} \\exp(-x) =0\nk_{n+1} = n^2 +k_n^2 - k_{n-1}\n\\dots\nF_{\\ell} = \\mathbb{P}\\{X - {\\ell} \\leq{x} | X > {\\ell} \\} = \\frac{F(x+ {\\ell}) - F(\\ell)}{1 - F_{X}\\{\\ell\\}}\n\nlibrary(Sim.DiffProc)\nmu=1;sigma=0.5;theta=2\n x0=0;y0=0;init=c(x0,y0)\nf <- expression(1/mu*(theta-x), x)  \ng <- expression(sqrt(sigma),0)\nmod2d <- snssde2d(drift=f,diffusion=g,M=500,Dt=0.015,x0=c(x=0,y=0))\n## true values of first and second moment at time 10\nEx <- function(t) theta+(x0-theta)*exp(-t/mu)\nVx <- function(t) 0.5*sigma*mu *(1-exp(-2*(t/mu)))\nEy <- function(t) y0+theta*t+(x0-theta)*mu*(1-exp(-t/mu))\nVy <- function(t) sigma*mu^3*((t/mu)-2*(1-exp(-t/mu))+0.5*(1-exp(-2*(t/mu))))\ncovxy <- function(t) 0.5*sigma*mu^2 *(1-2*exp(-t/mu)+exp(-2*(t/mu)))\ntvalue = list(m1=Ex(15),m2=Ey(15),S1=Vx(15),S2=Vy(15),C12=covxy(15))\n ## function of the statistic(s) of interest.\nsde.fun2d <- function(data, i){\n   d <- data[i,]\n   return(c(mean(d$x),mean(d$y),var(d$x),var(d$y),cov(d$x,d$y)))\n}\n ## Parallel Monte-Carlo of 'OUI' at time 10\nmcm.mod2d = MCM.sde(mod2d,statistic=sde.fun2d,time=15,R=10,exact=tvalue,parallel=\"snow\",ncpus=2)\nmcm.mod2d$MC\n\n         Exact   Estimate       Bias Std.Error      RMSE\nm1   1.9999994  2.0140861  0.0140867 0.0055712 0.0218581\nm2  28.0000006 27.9721715 -0.0278291 0.0312552 0.0978083\nS1   0.2500000  0.2445866 -0.0054134 0.0038780 0.0128319\nS2   6.7500003  6.5992153 -0.1507850 0.0799199 0.2832329\nC12  0.2499998  0.2157827 -0.0342171 0.0160072 0.0589651\n           CI( 2.5 % , 97.5 % )\nm1    ( 2.0031667 , 2.0250055 )\nm2  ( 27.9109124 , 28.0334306 )\nS1    ( 0.2369859 , 0.2521873 )\nS2    ( 6.4425752 , 6.7558554 )\nC12   ( 0.1844092 , 0.2471562 )\n\n\n\\begin{equation*}\n\\begin{cases}\n\\begin{split}\ndX_{t} &= \\left( \\alpha \\, X_{t} \\, \\left( 1 - \\frac{X_{t}}{\\beta} \\right) - \\frac{\\delta \\, X_{t}^2 \\, Y_{t}}{\\left( \\kappa + X_{t}^2 \\right)} \\right) \\:dt +  \\sqrt{\\sigma_{1}} \\, X_{t} \\, \\left( 1 - Y_{t} \\right) \\:dW_{1,t} \\\\\ndY_{t} &= \\left( \\frac{\\gamma \\, X_{t}^2 \\, Y_{t}}{\\left( \\kappa + X_{t}^2 \\right)} - \\mu \\, Y_{t}^2 \\right) \\:dt +  \\left| \\sigma_{2}\\right|  \\, Y_{t} \\, \\left( 1 - X_{t} \\right) \\:dW_{2,t}\n\\end{split}\n\\end{cases}\n\\end{equation*}\n\\begin{equation}\n\\begin{cases}\n\\begin{split}\n\\frac{d}{dt} m_{1}(t) ~&= \\frac{\\left( \\theta - m_{1}(t) \\right)}{\\mu} \\\\\n\\frac{d}{dt} m_{2}(t) ~&= m_{1}(t) \\\\\n\\frac{d}{dt} S_{1}(t) ~&= \\sigma - 2 \\, \\left( \\frac{S_{1}(t)}{\\mu} \\right) \\\\\n\\frac{d}{dt} S_{2}(t) ~&= 2 \\, C_{12}(t) \\\\\n\\frac{d}{dt} C_{12}(t) &= S_{1}(t) - \\frac{C_{12}(t)}{\\mu}\n\\end{split}\n\\end{cases}\n\\end{equation}\n\\begin{equation}\n\\left.\\begin{aligned}\n        B'&=-\\partial \\times E,\\\\\n        E'&=\\partial \\times B - 4\\pi j,\n       \\end{aligned}\n\\right\\}\n\\qquad \\text{Maxwell's equations}\n\\end{equation}"
  },
  {
    "objectID": "docu/SEA/index.html",
    "href": "docu/SEA/index.html",
    "title": "Sea of Everything",
    "section": "",
    "text": "Inspired by the Sea of foundations By Professro Ravi Vakil , which covers pretty much everything one needs to master Algebraic geometry. I have titled this section as Sea of Everything where i would be covering all my current interests related to fields of financial mathematics,programming , machine learning , crypto , etc…\nThis whole section under Sea of Everything would mostly function as a blog, conventional blogs are very badly designed and difficult to navigate as of now i have just decided to maintain my articles as part of this website. If it gets cumbersome to maintain I might convert the webpage into a full blown traditional blog , but I am skeptical as of now.\nMy Home page would host articles that I have written to explain myself the inner - working of an idea or a concept and which are fascinating enough to be highlighted amidst all of this.\nThe current direction of this section mostly looks like combination of notes and insights."
  },
  {
    "objectID": "math2.html",
    "href": "math2.html",
    "title": "Krishnakant A",
    "section": "",
    "text": "\\(\\alpha + \\beta\\)\n\\(\\Pi + \\Gamma\\)\n\\(a \\bmod b\\)\n\\(x \\equiv a \\pmod{b}\\)\n\\(\\lim\\limits_{x \\to \\infty} \\exp(-x) =0\\)\n\\(k_{n+1} = n^2 +k_n^2 - k_{n-1}\\)\n\\(\\dots\\)\n\nlibrary(Sim.DiffProc)\n\nPackage 'Sim.DiffProc', version 4.8\nbrowseVignettes('Sim.DiffProc') for more informations.\n\nmu=1;sigma=0.5;theta=2\n x0=0;y0=0;init=c(x0,y0)\nf <- expression(1/mu*(theta-x), x)  \ng <- expression(sqrt(sigma),0)\nmod2d <- snssde2d(drift=f,diffusion=g,M=500,Dt=0.015,x0=c(x=0,y=0))\n## true values of first and second moment at time 10\nEx <- function(t) theta+(x0-theta)*exp(-t/mu)\nVx <- function(t) 0.5*sigma*mu *(1-exp(-2*(t/mu)))\nEy <- function(t) y0+theta*t+(x0-theta)*mu*(1-exp(-t/mu))\nVy <- function(t) sigma*mu^3*((t/mu)-2*(1-exp(-t/mu))+0.5*(1-exp(-2*(t/mu))))\ncovxy <- function(t) 0.5*sigma*mu^2 *(1-2*exp(-t/mu)+exp(-2*(t/mu)))\ntvalue = list(m1=Ex(15),m2=Ey(15),S1=Vx(15),S2=Vy(15),C12=covxy(15))\n ## function of the statistic(s) of interest.\nsde.fun2d <- function(data, i){\n   d <- data[i,]\n   return(c(mean(d$x),mean(d$y),var(d$x),var(d$y),cov(d$x,d$y)))\n}\n ## Parallel Monte-Carlo of 'OUI' at time 10\nmcm.mod2d = MCM.sde(mod2d,statistic=sde.fun2d,time=15,R=10,exact=tvalue,parallel=\"snow\",ncpus=2)\nmcm.mod2d$MC\n\n         Exact   Estimate       Bias Std.Error      RMSE\nm1   1.9999994  2.0012785  0.0012791 0.0071115 0.0213728\nm2  28.0000006 27.9709325 -0.0290681 0.0461900 0.1415859\nS1   0.2500000  0.2446978 -0.0053022 0.0061740 0.0192661\nS2   6.7500003  6.3938382 -0.3561621 0.1191446 0.5045894\nC12  0.2499998  0.2117307 -0.0382691 0.0130157 0.0546737\n           CI( 2.5 % , 97.5 % )\nm1    ( 1.9873402 , 2.0152168 )\nm2  ( 27.8804018 , 28.0614632 )\nS1     ( 0.232597 , 0.2567986 )\nS2    ( 6.1603191 , 6.6273573 )\nC12    ( 0.1862204 , 0.237241 )\n\n\n\\[\\begin{equation*}\n\\begin{cases}\n\\begin{split}\ndX_{t} &= \\left( \\alpha \\, X_{t} \\, \\left( 1 - \\frac{X_{t}}{\\beta} \\right) - \\frac{\\delta \\, X_{t}^2 \\, Y_{t}}{\\left( \\kappa + X_{t}^2 \\right)} \\right) \\:dt +  \\sqrt{\\sigma_{1}} \\, X_{t} \\, \\left( 1 - Y_{t} \\right) \\:dW_{1,t} \\\\\ndY_{t} &= \\left( \\frac{\\gamma \\, X_{t}^2 \\, Y_{t}}{\\left( \\kappa + X_{t}^2 \\right)} - \\mu \\, Y_{t}^2 \\right) \\:dt +  \\left| \\sigma_{2}\\right|  \\, Y_{t} \\, \\left( 1 - X_{t} \\right) \\:dW_{2,t}\n\\end{split}\n\\end{cases}\n\\end{equation*}\\]\n\\[\\begin{equation}\n\\begin{cases}\n\\begin{split}\n\\frac{d}{dt} m_{1}(t) ~&= \\frac{\\left( \\theta - m_{1}(t) \\right)}{\\mu} \\\\\n\\frac{d}{dt} m_{2}(t) ~&= m_{1}(t) \\\\\n\\frac{d}{dt} S_{1}(t) ~&= \\sigma - 2 \\, \\left( \\frac{S_{1}(t)}{\\mu} \\right) \\\\\n\\frac{d}{dt} S_{2}(t) ~&= 2 \\, C_{12}(t) \\\\\n\\frac{d}{dt} C_{12}(t) &= S_{1}(t) - \\frac{C_{12}(t)}{\\mu}\n\\end{split}\n\\end{cases}\n\\end{equation}\\]\n\\[\\begin{equation}\n\\left.\\begin{aligned}\n        B'&=-\\partial \\times E,\\\\\n        E'&=\\partial \\times B - 4\\pi j,\n       \\end{aligned}\n\\right\\}\n\\qquad \\text{Maxwell's equations}\n\\end{equation}\\]\n\n# Load required packages\nlibrary(fpp3)\n\n── Attaching packages ──────────────────────────────────────────── fpp3 0.4.0 ──\n\n\n✔ tibble      3.1.8      ✔ tsibble     1.1.3 \n✔ dplyr       1.0.10     ✔ tsibbledata 0.4.1 \n✔ tidyr       1.2.1      ✔ feasts      0.3.0 \n✔ lubridate   1.9.0      ✔ fable       0.3.2 \n✔ ggplot2     3.4.0      \n\n\n── Conflicts ───────────────────────────────────────────────── fpp3_conflicts ──\n✖ lubridate::date()    masks base::date()\n✖ dplyr::filter()      masks stats::filter()\n✖ tsibble::intersect() masks base::intersect()\n✖ tsibble::interval()  masks lubridate::interval()\n✖ dplyr::lag()         masks stats::lag()\n✖ tsibble::setdiff()   masks base::setdiff()\n✖ tsibble::union()     masks base::union()\n\n# Plot one time series\naus_retail %>%\n  filter(`Series ID`==\"A3349640L\") %>%\n  autoplot(Turnover)\n\n\n\n# Produce some forecasts\naus_retail %>%\n  filter(`Series ID`==\"A3349640L\") %>%\n  model(ETS(Turnover)) %>%\n  forecast(h = \"2 years\")\n\n# A fable: 24 x 6 [1M]\n# Key:     State, Industry, .model [1]\n   State    Industry                          .model    Month     Turnover .mean\n   <chr>    <chr>                             <chr>     <mth>       <dist> <dbl>\n 1 Victoria Cafes, restaurants and catering … ETS(T… 2019 Jan  N(608, 978)  608.\n 2 Victoria Cafes, restaurants and catering … ETS(T… 2019 Feb N(551, 1129)  551.\n 3 Victoria Cafes, restaurants and catering … ETS(T… 2019 Mar N(622, 1856)  622.\n 4 Victoria Cafes, restaurants and catering … ETS(T… 2019 Apr N(609, 2190)  609.\n 5 Victoria Cafes, restaurants and catering … ETS(T… 2019 May N(602, 2539)  602.\n 6 Victoria Cafes, restaurants and catering … ETS(T… 2019 Jun N(577, 2704)  577.\n 7 Victoria Cafes, restaurants and catering … ETS(T… 2019 Jul N(607, 3413)  607.\n 8 Victoria Cafes, restaurants and catering … ETS(T… 2019 Aug N(626, 4072)  626.\n 9 Victoria Cafes, restaurants and catering … ETS(T… 2019 Sep N(614, 4358)  614.\n10 Victoria Cafes, restaurants and catering … ETS(T… 2019 Oct N(624, 4942)  624.\n# … with 14 more rows"
  },
  {
    "objectID": "docu/Book_Implementations/index.html",
    "href": "docu/Book_Implementations/index.html",
    "title": "Book Implementations",
    "section": "",
    "text": "As the name suggests this section deals with various technical books that have read and most importantly their code implementation.\nCurrent plan is write code and look at the code."
  },
  {
    "objectID": "docu/SEA/Q_F/index.html#title-quantitative-finance",
    "href": "docu/SEA/Q_F/index.html#title-quantitative-finance",
    "title": "Krishnakant A",
    "section": "title: “Quantitative Finance”",
    "text": "title: “Quantitative Finance”\nThis topic mainly covers stochastic calculus , I find the theory and its applications within finance quite interesting, the reason why I have to not included this section inside mathematics is mostly because I stumbled across this topic when I had started reading option theory, though i had heard of it during my graduate program but never found it interesting and never gave a second thought about, Interestingly enough I got interested in the topic once I realised I won’t be pursuing a PH.D in Math.\nThere is(was) a great course on Stochastic process by Higher School of Economics(Russia) on coursera which i happened to complete.\nI have as of now also included Econometrics as part of Quant finance against popular opinion since everything is just a linear regression.\nFuture topics might include Market Risk Analysis , the four volume set on Market risk analysis by Carol Alexander are a gem. I happened to come across it while i was preparing for my FRM exams."
  },
  {
    "objectID": "docu/SEA/Q_F/index.html",
    "href": "docu/SEA/Q_F/index.html",
    "title": "Quantitative Finance",
    "section": "",
    "text": "This topic mainly covers stochastic calculus , I find the theory and its applications within finance quite interesting, the reason why I have decided to not included this section inside mathematics is mostly because I stumbled across this topic when I had started reading option theory, though i had heard of it during my graduate program but never found it interesting and never gave a second thought about it. Oddly enough I got fascinated with the topic once I realised I won’t be pursuing a PH.D in Math.\nThere is(was) a great course on Stochastic process by Higher School of Economics(Russia) on coursera which i happened to complete.\nI have as of now also included Econometrics as part of Quant finance against popular opinion since everything is just a linear regression.\nFuture topics might include Market Risk Analysis , the four volume set on Market risk analysis by Carol Alexander is a gem. I happened to come across it while i was preparing for my FRM exams."
  },
  {
    "objectID": "docu/posts/firstpost.html",
    "href": "docu/posts/firstpost.html",
    "title": "Quantitative finance resources",
    "section": "",
    "text": "Quantitative finance is vast field with lot many resources available. Many would agree these resources would help one get a job and be at intermediate level in terms of expertise, while becoming a expert is still sort of restricted to learning on the job. But can one ever become an expert in any chosen topic within Quantitative finance or even for that matter get to an intermediate level of understanding of various topics within the field.\n\n\n\n\nOne of the most difficult decisions that I had to make while venturing into this field was choose a book to read or videos to watch and stick to it without regretting later that it wasn’t enough or worse I chose the wrong resource. Educating oneself for the purpose of research in purely theoretical field is far more simple, you know for sure the list of prerequistes for the topic , the books that you need to master the topic, current and past important research papers you need to read and research work by list of researchers you need to follow voilà you are close to becoming an expert in the field given of course you have had comprehensive understanding of the topic which you are able explain with relative ease. A researcher lets say in the field of pure mathematics doesnt care whether his research is going to be relevant in next 10 years or 20 years,for him the joy lies in solving the problem and coming up with innovative solution , it hardly matters whether his research topic will be relevant for he has gained a level of expertise to such an extent that such a thing were ever to bother him he would just shift his focus in a closely related field(assuming there is always a closely related field) of relevance with minimal difficulty and at time same time continue doing research on the topic and hoping there would be someone who might pursue it further later on.\nThis approach of the researcher I think is the best way to move forward in learning any topic. Make yourself an expert in the basics of the field and you are free to move around without the overhead of being relevant or for that matter employable. To worry about whether the resource you have chosen to master a topic is enough or not gets you no where. \nThere are lot many topics within the field of quantitative finance for one to come closer to becoming an expert.\nOn the internet you will find lot many articles listing resources based on each topic. In the end they even go on to say the list is not exhaustive making even more difficult to choose. I think its nearly impossible to cover that many books( they could just be resources for reference but that’s hardly ever the tone of those articles) in any reasonable amount of time.\nYou can refer to the resources section up top for list of all books , articles , youtube video that I have come across over the period of time. Here I have just listed down couple of books on each topic and contents of each topics that one needs to master(based on job description for almost any type of quantitative role) and that can be completed in a reasonable amount of time(give yourself a year or six months if you are really comfortable with the math ). I have included books that are at times quite math heavy since I prefer them more and I have a background(Masters) in pure(non-applicable) mathematics. I would suggest to get comfortable with math for it becomes easier in manipulating models and creating new ones from the existing models without much effort. This is particularly true in this field as one proceeds with the assumption that all models are wrong, math would help you in converging to the reality (ironically).Try to implement the mathematical topics in a programming language of your choice instead of postponing it.\nHere is the list of resources that I am currently reading and following:\n\nStatistics and probability\nA. Topics\n\nProbability and distributions (All the common and standard distributions)\nMultivariate distributions\nStastical inference\nMaximum likelikhood methods\nSufficiency\nGeneralised linear models\nLimiting Distributions\nOptimal tests of hypothesis\nNon parametric and robust statistics\n\nB. Books and videos\n\nIntroudction to mathematical statistics by Hogg ,Mckean and Craig\nMathematical theory of Bayesian Mathematics by Sumio Watanabe\nStatistics for Application by Philippe Rigollet (Youtube video - MIT OCW)\n\nMachine learning and deep learning\nA. Topics\n\nSupervised learning algorithms\nUnsupervised Learning Algorithms\nAdvanced learning algorithims\n\nB Books and Videos\n\n[Theory]Probabilistic Machine learning Book 1 by Kevin Murphy\n[Theory]Understanding Machine learning theory algorithims\nISLR[Introduction to statistical learnign - good for R implementation] and ESL[Elements of statistical learning- Bible of Statistical Learning] by Hastie and Tibshirani\n[Implementation] Hands-On Machine Learning with Scikit-Learn, Kera & Tensorflow by Aurelien Geron\n[Bonus Implementation] Machine Learing in C++ by Kiril Kolodiazhnyi\n[Coursera - Deep Learning.ai - Andrew Ng] Machine Learning Specialization(This course enough for all intents and purposes unless you wish to delve deeper)\n\nStochastic calculus[An absolute on Sell Side]\nA. Topics\n\nMeasure theoretic Probability\nBrownian Motion\nIto’s Integral [the most important subtopic]\nIto-Doeblin Formula\nLevy Process and Jump Process\nChange of Numeraire\nTerm Structure Models\n\nB. Books and videos\n\nStochastic Calculus for finance II by Steven E Shreve [This is enough for all intents and purposes] but if you are interested in Levy processes than you might have to refer to another book.\nMathematical Modeling and computation in finance by Cornelis W Oosterlee and Lech A Grezelak (You can find videos which follow the book by the later author on you tube making it one of the most approachable resource on the topic) I would sugget to go through this text once, before you go for Shreve’s book. Shreve’s book extensively makes use of Measure Theory.Great theoretical and practical book. I personally use this book and shreve’s book for refernce. TO be honest no stochastic calculus for finance book actually is self contained, many theorems are referenced.\nPricing options with Mathematical Models (great course on coursera ) from Caltech.\n\nMathematics relevant for finance\nFinancial products (Mostly Options)\nProgramming tools\nA. Topics\nScientific Computing\nTradFi(Traditional Finance)"
  },
  {
    "objectID": "docu/Twitter_SS.html",
    "href": "docu/Twitter_SS.html",
    "title": "Resources(Mostly Twitter S/S)",
    "section": "",
    "text": "This page basically contains twitter threads screen shots , there is no easy way to save twitter threads on twitter and save them or at least i haven’t bothered to search for a solution ,so anyways would be including it here\nAs of now I haven’t categorized it and maybe in future will add links and reviews to various resources which i have found useful over time.\nThe date, time and twitter_handle is included in the screen-shot so you can go ahead and search for it , I have not purposefully included them the links since many a times the author deletes the tweets and it becomes a headache to revist dead-links and remove them , trying to keep it simple here."
  },
  {
    "objectID": "docu/Resources/index.html",
    "href": "docu/Resources/index.html",
    "title": "Resources(Mostly Twitter S/S)",
    "section": "",
    "text": "This page basically contains twitter threads screen shots , there is no easy way to save twitter threads on twitter and save them or at least i haven’t bothered to search for a solution ,so anyways would be including it here\nAs of now I haven’t categorized it and maybe in future will add links and reviews to various resources which i have found useful over time.\nThe date, time and twitter_handle is included in the screen-shot so you can go ahead and search for it , I have not purposefully included them the links since many a times the author deletes the tweets and it becomes a headache to revist dead-links and remove them , trying to keep it simple here."
  },
  {
    "objectID": "docu/SEA/time_series.html",
    "href": "docu/SEA/time_series.html",
    "title": "Time Series and Econometric Analysis",
    "section": "",
    "text": "Time series analysis by James D Hamilton - its considered to be the bible on time series analysis, pretty much covers all the theory , it doesnt have any code or pseudocode\nIntroduction to Time Series with R by Metcalfe & Coweperwait\nAnalysis of Financial Time Series by Tsay\n\n\n\n\n\nWould be exploring time series analysis in the context of finance\nImplementing code from the books above later 2 books mentioned above, would be using the book by Hamilton as reference\nAim to understand different time series models in R.\n(Will keep on adding the aims as is go on)"
  },
  {
    "objectID": "docu/SEA/MRA.html",
    "href": "docu/SEA/MRA.html",
    "title": "Market Risk Analysis",
    "section": "",
    "text": "The best book i found for this topic is by Prof. Carol Alexanders , its a four volume text. Recently she made the accompanying excel files available for free making the text and content even more approachable.\nWould be adding topics of interest from those books in various sections of this site"
  },
  {
    "objectID": "docu/SEA/time_series.html#part-1",
    "href": "docu/SEA/time_series.html#part-1",
    "title": "Time Series Analysis",
    "section": "Part 1",
    "text": "Part 1\n\nDifference operators\nasd\n\n\nLag operators\nsdf\n\n\nStationary ARMA Process\nsadf\n\n\nForecasting\nsadf\n\n\nMaximum likelihood Estimation\nsadf\n\n\nSpectral Analysis\nasdf"
  },
  {
    "objectID": "docu/Resources/index.html#quantitative-finance",
    "href": "docu/Resources/index.html#quantitative-finance",
    "title": "Resources(Mostly Twitter S/S)",
    "section": "Quantitative Finance",
    "text": "Quantitative Finance\n\nStochastic Calculus"
  },
  {
    "objectID": "docu/Resources/index.html#mathematics",
    "href": "docu/Resources/index.html#mathematics",
    "title": "Resources(Mostly Twitter S/S)",
    "section": "Mathematics",
    "text": "Mathematics\n\nStatistics"
  },
  {
    "objectID": "docu/Resources/index.html#programming",
    "href": "docu/Resources/index.html#programming",
    "title": "Resources(Mostly Twitter S/S)",
    "section": "Programming",
    "text": "Programming\n\nR\n\n\nPython\n\n\nC+++\n\n\nRust"
  },
  {
    "objectID": "docu/Resources/index.html#data-science-machine-learning-and-deep-learning",
    "href": "docu/Resources/index.html#data-science-machine-learning-and-deep-learning",
    "title": "Resources(Mostly Twitter S/S)",
    "section": "Data Science , Machine Learning and Deep learning",
    "text": "Data Science , Machine Learning and Deep learning"
  },
  {
    "objectID": "docu/Resources/index.html#trading",
    "href": "docu/Resources/index.html#trading",
    "title": "Resources(Mostly Twitter S/S)",
    "section": "Trading",
    "text": "Trading"
  },
  {
    "objectID": "docu/Resources/index.html#tradfi-and-finance-books",
    "href": "docu/Resources/index.html#tradfi-and-finance-books",
    "title": "Resources(Mostly Twitter S/S)",
    "section": "TradFi and Finance books",
    "text": "TradFi and Finance books"
  },
  {
    "objectID": "docu/SEA/python.html",
    "href": "docu/SEA/python.html",
    "title": "Python Programming language",
    "section": "",
    "text": "High Level language - Strong abstraction, easy to use and easy to understand syntax.\nGeneral purpose programming language\nIndentation important\nCase Sensitive\nSupports multiple programming paradigms such OOP and functional\nExcellently documented and comprehensive standard library\nDynamically but Strongly typed - Types are checked at run time and forbids operations that are not of the same type\nGarbage collected - Automatic memory management"
  },
  {
    "objectID": "docu/SEA/StochC.html",
    "href": "docu/SEA/StochC.html",
    "title": "Stochastic Calculus",
    "section": "",
    "text": "These are list of books , videos and courses that I am currently referencing for content on this page , for more detailed list please check out the resource section above.\n\nMathematical modelling and computation in finance by Cornerlis Ooseterlee and Lech Grzelak (Main Text)\nStochastic CalcuIus for Finance II Continuous-Time Models by Steven Shreve (Main Reference text)\nStochastic Differential Equations By Bernt Oksendal"
  },
  {
    "objectID": "docu/SEA/StochC.html#algebra",
    "href": "docu/SEA/StochC.html#algebra",
    "title": "Stochastic Calculus",
    "section": "algebra",
    "text": "algebra\nLet be a nonempty set , and let"
  },
  {
    "objectID": "docu/SEA/StochC.html#line",
    "href": "docu/SEA/StochC.html#line",
    "title": "Stochastic Calculus",
    "section": "Line",
    "text": "Line\nThe equation of any straight line, called a linear equation, can be written as:\n\ny = mx + b\n :::\nSee ?@def-line."
  },
  {
    "objectID": "docu/SEA/StochC.html#sigma-algebra",
    "href": "docu/SEA/StochC.html#sigma-algebra",
    "title": "Stochastic Calculus",
    "section": "\\sigma algebra",
    "text": "\\sigma algebra\nLet \\Omega be a nonempty set , and let \\mathbb{F} \ny = mx + b"
  },
  {
    "objectID": "docu/SEA/Machine Learning.html",
    "href": "docu/SEA/Machine Learning.html",
    "title": "Machine Learning",
    "section": "",
    "text": "##Introduction\n##Resources\n##Supervised Learning \n###Linear Regression\n###Logistic Regression"
  },
  {
    "objectID": "docu/SEA/Machine Learning.html#resources",
    "href": "docu/SEA/Machine Learning.html#resources",
    "title": "Machine Learning",
    "section": "Resources",
    "text": "Resources\n\nBooks:\n\nHands on Machine Learning with Sckit-Learn, Keras & TensorFlow by Aurelien Geron\n\nIntroduction to Statistical Learning (ISLR) Hastie and Tibshirani\nElements of Statistical Learning By Hastie and Tibshirani"
  },
  {
    "objectID": "docu/SEA/Machine Learning.html#supervised-learning",
    "href": "docu/SEA/Machine Learning.html#supervised-learning",
    "title": "Machine Learning",
    "section": "Supervised Learning",
    "text": "Supervised Learning\n\n\nLinear Regression\n\n\nLogistic Regression"
  },
  {
    "objectID": "docu/SEA/python.html#basics",
    "href": "docu/SEA/python.html#basics",
    "title": "Python Programming language",
    "section": "Basics",
    "text": "Basics\n\nThe Python Standard Library\n\nBuilt-in types\n\nlist ,tuple, set, dict and others\n\nBuilt-in functions\n\nprint() , len() ,range(),enumerate(),map(),zip() and others\n\nBuilt-in modules\n\nos,sys,itertools,collecations,math and others"
  },
  {
    "objectID": "docu/SEA/practice.html",
    "href": "docu/SEA/practice.html",
    "title": "Quarto HTML Basics",
    "section": "",
    "text": "This a Quarto document. To learn more about Quarto see https://quarto.org.\nClick the Code button in the header to see the full source code of this document.\nHere we call the R summary() function—the function’s output is included immediately below:\n\nsummary(cars)"
  },
  {
    "objectID": "docu/SEA/practice.html#plot-output",
    "href": "docu/SEA/practice.html#plot-output",
    "title": "Quarto HTML Basics",
    "section": "Plot Output",
    "text": "Plot Output\nYou can also embed plots, for example:\n\nlibrary(ggplot2)\ndat <- data.frame(cond = rep(c(\"A\", \"B\"), each=10),\n                  xvar = 1:20 + rnorm(20,sd=3),\n                  yvar = 1:20 + rnorm(20,sd=3))\n\nggplot(dat, aes(x=xvar, y=yvar)) +\n    geom_point(shape=1) + \n    geom_smooth() \n\nNote that the code-fold: true parameter was added to the code chunk to hide the code by default (click “Code” above the plot to see the code).\nThe use of the label and fig-cap options make this a cross-referenceable figure (see )."
  },
  {
    "objectID": "docu/SEA/practice.html#interactivity",
    "href": "docu/SEA/practice.html#interactivity",
    "title": "Quarto HTML Basics",
    "section": "Interactivity",
    "text": "Interactivity\nYou can also add interactive plots. For example:\n\nlibrary(dygraphs)\ndygraph(nhtemp) %>% \n  dyRangeSelector(dateWindow = c(\"1920-01-01\", \"1960-01-01\"))"
  },
  {
    "objectID": "docu/SEA/practice.html#tables",
    "href": "docu/SEA/practice.html#tables",
    "title": "Quarto HTML Basics",
    "section": "Tables",
    "text": "Tables\nUse the knitr::kable() function to print tables as HTML:\n\nknitr::kable(head(ggplot2::diamonds))"
  },
  {
    "objectID": "docu/SEA/practice.html#latex-math",
    "href": "docu/SEA/practice.html#latex-math",
    "title": "Quarto HTML Basics",
    "section": "LaTeX Math",
    "text": "LaTeX Math\nYou can also include LaTeX math:\n\nP\\left(A=2\\middle|\\frac{A^2}{B}>4\\right)"
  },
  {
    "objectID": "docu/SEA/StochC.html#general-probability-theory",
    "href": "docu/SEA/StochC.html#general-probability-theory",
    "title": "Stochastic Calculus",
    "section": "General Probability theory",
    "text": "General Probability theory\n\nDefinition 1 (\\sigma algebra) : Let \\Omega be a nonempty set , and let \\mathcal{F} be a set of collections of subsets of \\Omega. We say that \\mathcal{F} is a \\sigma algebra provided that\n\nThe empty set \\emptyset belongs to \\mathcal{F}\nA and A^{c} belong to \\mathcal{F} whenever A \\in \\mathcal{F}\nwhenever A_1 ,A_2 ,A_3 ..... \\in \\mathcal{F} then \\bigcup_{i=1}^\\infty A_{i} \\in \\mathcal{F}\n\n\n \n\nDefinition 2 (Probability measure) : Let \\Omega be a nonempty set , and let \\mathbb{F} be \\sigma algebra of subsets of \\Omega. A probability measure \\mathbb{P} is a function that, to every set A \\in \\mathcal{F} , assigns a number in [0,1] called the probability of A written as \\mathbb{P}(A) .We require\n\n\\mathbb{P}(\\Omega) = 1 and\n(Countable Additivity) Whenever A_1,A_2,A_3.... is a sequence of disjoint sets in \\mathcal{F} , then \\mathbb{P}(\\bigcup_{n=1}^\\infty A_n) = \\sum_{n=1}^{\\infty} \\mathbb{P}(A_n) \n\n The Triple (\\Omega, \\mathcal{F},\\mathbb{}P) is called probability measure\n\n From the above it follows that for finitely many disjoint sets A_1, A_2,A_3....A_n \\mathbb{P}(\\bigcup_{n=1}^N) = \\sum_{n=1}^N \\mathbb{P}(A_n)\nand \\mathbb{P}(A^c) = 1 - \\mathbb{P}(A)\n\nExample 1 (Uniform(Lebesgue) measure on [0,1])  \\Omega = [0,1] \\mathbb{P}[a,b] = b-a ,0 \\leq a \\leq b \\leq1  single points have zero probability and  (a,b) can be written as  \\bigcup_{n=1}^\\infty[a+\\frac{1}{n} , b -\\frac{1}{n}]\n\n  The \\sigma-algebra beginning with closed intervals and adding everything else necessary in order to have a \\sigma- algebra is called a Borel \\sigma-algebra and denoted by \\mathcal{B}[0,1]. Borel \\sigma-algebras are \\sigma-algebra generated by open sets and equivalently closed sets over any topological space.\n\nDefinition 3 let (\\Omega,\\mathcal{F},\\mathbb{P}) be a probability space. If a set A \\in \\mathcal{F} satisfies \\mathbb{P}(A) = 1, we say the event A occurs almost surely\n\n\nExample 2 Let \\mathbb{P} be the uniform measure as defined in example 1. Define X(\\omega) = \\omega and Y(\\omega) = 1 - \\omega for all \\omega \\in [0,1] , then the distribution measure of X is uniform \\mu_{X}[a,b] = \\mathbb{P}\\{\\omega;a\\leq X(w)\\leq b\\} = \\mathbb{P}[a,b] = b-a, 0\\leq a \\leq b \\leq 1 by definition of \\mathbb{P}.  Its easy to see to see that X and Y have the same distribution. But under the probability measure\\mathbb{\\widetilde{P}} on [0,1] defined by \\mathbb{\\widetilde{P}[a,b]} = \\int_a^b 2\\omega \\, d\\omega = b^2-a^2  , 0 \\leq a\\leq b \\leq1  X and Y have different distributions.\n\n\nDefinition 4 (cumulative distribution function and density function)  F(x) = \\mathbb{P}\\{X \\leq x\\} , x \\in \\mathbb{R} \\mu_X[a,b] = \\mathbb{P}\\{a \\leq X \\leq b \\} = \\int_a^b f(x) \\, dx , -\\infty < a \\leq b < \\infty f(x) is called the density funtion and F(x) is called the cummulative distribution function.\n\n\nExample 3 (Standard normal random variable) Let \\phi(x)  = \\frac {a}{\\sqrt{2\\pi}}e^{\\frac{-x^2}{2}} be the standard normal density and definiing the cummulative normal distribution function as N(x) = \\int_{-\\infty}^x \\phi(\\xi)\\,d\\xi The function N(x) is strictly increasing function which is surjective onto (0,1) from \\mathbb{R}, so it has a strictly increasing inverse function N^{-1}(y),y \\in (0,1). Let Y be a uniformly distributed random variable defined on some probability space (\\Omega,\\mathcal{F},\\mathbb{P}) and set X = N^{-1}(Y) then\n\\begin{align*}\n\n\\mu_X[a,b] &= \\mathbb{P}\\{\\omega \\in \\Omega ; a \\leq X(\\omega) \\leq b\\} \\\\\n\n          &= \\mathbb{P}\\{\\omega \\in \\Omega ; a \\leq N^{-1}(Y(\\omega)) \\leq b\\}\\\\\n            \n          &= \\mathbb{P}\\{\\omega \\in \\Omega ; N(a) \\leq Y(\\omega) \\leq N(b) \\} \\\\\n        \n          &= N(b) - N(a) \\\\\n          &= \\int_a^b \\phi(x) \\, dx\n\n\\end{align*}\nAny random variable that has this distribution regardless of the probability space is called standard normal distribution. Thing to note the use of uniformly distributed random variable for generating a standard random variable is called probability integral transform and this is commonly used in Monte Carlo simulation"
  },
  {
    "objectID": "docu/SEA/index.html#learning-approach",
    "href": "docu/SEA/index.html#learning-approach",
    "title": "Sea of Everything",
    "section": "Learning approach",
    "text": "Learning approach\nI would be going with top - down approach rather than a bottoms-up approach, a quicker way surely would be sacrificing some important theorems along the way if there are not used in any models , but for all practical purposes bottoms-up approach with a full time job is time consuming and I would have to wait almost a year to even see models and implementation going by that route."
  },
  {
    "objectID": "docu/SEA/StochC.html#brownian-motion",
    "href": "docu/SEA/StochC.html#brownian-motion",
    "title": "Stochastic Calculus",
    "section": "Brownian Motion",
    "text": "Brownian Motion"
  },
  {
    "objectID": "docu/SEA/StochC.html#learning-approach",
    "href": "docu/SEA/StochC.html#learning-approach",
    "title": "Stochastic Calculus",
    "section": "Learning approach",
    "text": "Learning approach\nI would be going with top - down approach rather than a bottoms-up approach, a quicker way surely would be sacrificing some important theorems along the way if they are not used in any models , but for all practical purposes bottoms-up approach with a full time job is time consuming and I would have to wait almost a year to even see models and implementation going by that route."
  },
  {
    "objectID": "docu/SEA/financial_products.html",
    "href": "docu/SEA/financial_products.html",
    "title": "Financial Products",
    "section": "",
    "text": "Option Volatility and Pricing by Sheldon Natenberg\nOptions, Futures and Other Derivatives by John C. Hull"
  },
  {
    "objectID": "docu/SEA/financial_products.html#content",
    "href": "docu/SEA/financial_products.html#content",
    "title": "Financial Products",
    "section": "Content",
    "text": "Content"
  },
  {
    "objectID": "docu/SEA/StochC.html#black-scholes-model",
    "href": "docu/SEA/StochC.html#black-scholes-model",
    "title": "Stochastic Calculus",
    "section": "Black-Scholes model",
    "text": "Black-Scholes model"
  },
  {
    "objectID": "docu/SEA/Crypto/evmdefi.html",
    "href": "docu/SEA/Crypto/evmdefi.html",
    "title": "DEFI and its related content",
    "section": "",
    "text": "[Motivation]Order book mechaisms are dominant medium of exchange of electronic assets in traditional finance but are quite challenging to use in smart contract environmen since the size of the state needed by an order book to represent the set of outstanding orders is large and extremely costly in the smart contract environment as users must pay for space and compute power utilized.\nA constant product market maker is a market for trading coins of type \\(\\alpha\\) for coins of type \\(\\beta\\). This market has reserves \\(R_\\alpha > 0\\) $R_> 0 $, contstant product \\(k = R_\\alpha R_\\beta\\), and percentage fee \\((1-\\gamma)\\). A transaction in this market , trading $> 0 $ coins \\(\\beta\\) for $> 0 $ for coins \\(\\alpha\\) , must satisfy \\[ (R_\\alpha - \\Delta_\\alpha)(R_\\beta + \\gamma\\Delta_\\beta) = k\\] Its clear to see that the constant terms comes from the product of the two reserves at any given time is always equal to \\(k\\)"
  },
  {
    "objectID": "docu/SEA/time_series.html#financial-time-series-and-linear-time-series",
    "href": "docu/SEA/time_series.html#financial-time-series-and-linear-time-series",
    "title": "Time Series and Econometric Analysis",
    "section": "Financial Time Series and Linear Time series",
    "text": "Financial Time Series and Linear Time series\n\nAsset Returns\n\nDefinition 1 (Simple gross return)  Arithmetic Returns\nP_t = P_{t-1}(1+R_t) \\implies R_t = \\frac{P_t - P_{t-1}}{P_t} where P_t and R_t are the price and return at time t respectively  Continuously compounded return or log return\nr_t = \\ln(1+R_t)  Dividend Payment\nr_t = \\ln(P_t + D_t) -\\ln(P_{t-1}) Where D_t is dividend payment between time t-1 and time t .\n\n\n\nDefinition 2 (Multiperiod gross return)  Similiary we can define multiperiod simple return by  R_t[k] = exp{[\\frac{1}{k}\\sum_{j=0}^{k-1}(1+R_{t-j})]} -1 where exp is the exponentential function and k is total number periods the asset was held for.\nLog return would be  r_t[k] = r_t +r_{t-1}+.....+r_{t-k+1}\n\n\nDefinition 3 (Portfolio Return) R_{p,t}= \\sum_{i=1}^{N}w_i R_{it}\nWhere p is the portfolio , i the ith asset and w_i the weight of the ith asset in the portofolio\n\n* Load data and header =T give the 1st row of the data file , that is the names of the cloumns of the data set\n\n# da contains the return for 5 five stocks and indexes namely IBM ,value-weighted , equal-weighted and S&P composite index from 1970 to 2008\nlibrary(fBasics)\nda = read.table(\"TST/d-ibm3dx7008.txt\",header = T) \ndim(da) # dimensions for the data\n\n[1] 9845    5\n\nda[1:5,]\n\n\n\n  \n\n\ntail(da)#first row\n\n\n\n  \n\n\nibm = da[,2] # IBM simple returns\n\nsibm = ibm*100 #Percentage simple returns \n\nbasicStats(sibm)\n\n\n\n  \n\n\ns1 = skewness(sibm)\nt = s1/sqrt(6/9845) #defintion for test statistic here 9845 is N \nt\n\n[1] 2.487093\nattr(,\"method\")\n[1] \"moment\"\n\npv  = 2*(1-pnorm(t)) # Calculate p-value\npv\n\n[1] 0.01287919\nattr(,\"method\")\n[1] \"moment\"\n\n\n\nlibrary(ggplot2)\nibm = as.data.frame(da[,1:2])\nibm[\"log_return\"] = log(1+ibm[\"rtn\"])\ncolnames(ibm)[2] <- \"simple_return\"\nggplot(ibm,aes(x = simple_return,colour = \"Emperical\"))+ggtitle(\"Simple return distribution\") + xlim (-0.15,0.15)+geom_density()+stat_function(mapping = aes(colour = \"Normal\"),\nfun = dnorm,args = with(ibm,c(mean =mean(simple_return),sd = sd(simple_return))))\nggplot(ibm,aes(x = log_return,colour = \"Emperical\"))+ggtitle(\"Log return distribution\") + xlim (-0.15,0.15)+geom_density()+\nstat_function(mapping = aes(colour = \"Normal\"),\nfun = dnorm,args = with(ibm,c(mean = mean(log_return),sd = sd(log_return))))+\nscale_x_continuous(\"log return distribution\",limits = c(-0.15,0.15))\n#stat_function(\n#fun = dnorm,args = with(ibm,c(mean =mean(simple_return),sd = sd(simple_return))))+\n\n\n\n\n\n\n\n\n\n\n\n\nibm1 = ibm[, 2]\nplot(ibm1,type = 'l')\n\n\n\nibm2 = ts(ibm1,frequency = 250 ,start = c(1970,1))\nplot.ts(ibm2)\n\n\n\nacf(ibm1,lag =250,ylim= c(-0.05,0.05))\n\n\n\nacf(ibm2,lag=250,ylim= c(-0.05,0.05))\n\n\n\n\n\n\nLinear Time Series\n\nDefinition 4 (Stationarity) Foundation of time series analysis is Stationarity. A time series \\{r_t\\} is said to be strictly stationary if the joint distribution of (r_{t_{1}},r_{t_{2}},r_{t_{3}},....,r_{t_{k}}) is identical to that of (r_{t_{1+t}},r_{t_{2+t}},r_{t_{3+t}},....,r_{t_{k+t}}) for all t , where k is an arbitrary positive integer and (t_1,t_2,t_3,....,t_k) is collection of k positive integers. Strict stationarity is very hard to verify emperically  A time series is said to be weakly stationary if the mean of r_t and the covariance between r_t and r_{t-l} are time invariant where l is an arbitrary integer. Weak stationarity enables us to make inference cooncerning future observations\nWeak stationarity is commonly studied and more practical.\nThe covariance \\gamma_l = Cov(r_t,r_{t-l}) is called the lag-l autocovariance of r_t. From the above defintion it follows that\n\n\\gamma_0=Var(r_t)\n\\gamma_{-l} = \\gamma_l"
  },
  {
    "objectID": "docu/SEA/Q_F/statistics.html#title-statistics",
    "href": "docu/SEA/Q_F/statistics.html#title-statistics",
    "title": "Krishnakant A",
    "section": "title: Statistics",
    "text": "title: Statistics"
  },
  {
    "objectID": "docu/SEA/Q_F/statistics.html#introduction",
    "href": "docu/SEA/Q_F/statistics.html#introduction",
    "title": "Krishnakant A",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "docu/SEA/Q_F/statistics.html#model-limitations",
    "href": "docu/SEA/Q_F/statistics.html#model-limitations",
    "title": "Krishnakant A",
    "section": "Model limitations",
    "text": "Model limitations\n\nNormal Distribution\n\nasd"
  },
  {
    "objectID": "docu/SEA/Q_F/statistics.html#distributions",
    "href": "docu/SEA/Q_F/statistics.html#distributions",
    "title": "Statistics",
    "section": "Distributions",
    "text": "Distributions\n\nNormal Distribution\nA random variable \\(X\\) is said to be normally distrbuted if it has a probability density function as follows\n\\[f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-{\\frac{1}{2}}(\\frac{x-\\mu}{\\sigma})^2}\\]\nIt is a continous probability distribution\n\\(\\mu\\) and \\(\\sigma\\) are the mean and variance of the distribution respectively\nThe case where \\(\\mu =0\\) and \\(\\sigma = 1\\) is called standard normal distribution and its PDF is given by \\[  f(x) =\\frac{1}{\\sqrt{2\\pi}}e^{\\frac{-x^2}{2}}\\]\n\n\nLog Normal Distibution\nA random Variable \\(X\\) is said to have log normal distibution if \\(Y = \\ln{X}\\) and \\(Y\\) is normally distributed.\nThe PDF of log normal distribution is given by\n\\[f(x) = \\frac{1}{x\\sigma\\sqrt{2\\pi}}e^{(-\\frac{(\\ln{x} -\\mu)^2}{2{\\sigma}^2})}\\] where \\(\\mu\\) and \\(\\sigma\\) are the mean and variance of \\(Y(\\ln X)\\) respectively.\nHence the mean \\(\\mu^*\\) and variance \\(\\sigma^*\\) of X are as follows\n\\[\\mu^* = e^{\\mu + \\frac{1}{2}\\sigma^2}\\] \\[\\sigma^* = e^{2\\mu + 2\\sigma^2} - e^{2\\mu +\\sigma^2}\\] Important thing to note here is that \\(x\\) can take values in \\((0,\\infty)\\) only."
  },
  {
    "objectID": "docu/SEA/Q_F/statistics.html#standard-definitions",
    "href": "docu/SEA/Q_F/statistics.html#standard-definitions",
    "title": "Statistics",
    "section": "Standard Definitions",
    "text": "Standard Definitions\nExpected Value \\(\\mathbb{E}[X]\\) is given by\n\\[\\mathbb{E}[X] = \\int_{-\\infty}^{\\infty}x f(x) dx\\] Variance\\(Var(X)\\) is given by\n\\[Var(X) = \\mathbb{E}(X^2) - \\mathbb{E}{{(X)}^2}\\] \\[Var(X) = \\int_{-\\infty}^{\\infty}(x-\\mathbb{E}[X])^2 f_X(x) dx\\] Higher Moments \\(\\mathbb{E}(X^n)\\) is given by\n\\[\\mathbb{E}(X^n) = \\int_{-\\infty}^{\\infty}x^n f_X(x) dx \\] Characteristic function(CHF) \\(\\phi_X(u)\\) for \\(u \\in \\mathbb{R}\\) is given by\n\\[\\phi_X(u) = \\mathbb{E}[e^{iuX}] = \\int_{-\\infty}^{\\infty}e^{iuX}f(x)dx \\]\nMoment generating function\\(\\mathcal{M}_X(u)\\) is given by \\[\\mathcal{M}_X(u) = \\phi_X(-iu)= \\mathbb{E}[e^{uX}] = \\int_{-\\infty}^{\\infty}e^{ux}f(x)dx \\] Cumulant characteristic function \\(\\zeta_X(u)\\) is given by \\[\\zeta_X(u) = log\\mathbb{E}[e^{iux}] = log\\phi_X(u)\\]"
  },
  {
    "objectID": "docu/SEA/Q_F/statistics.html#univaiate-distributions",
    "href": "docu/SEA/Q_F/statistics.html#univaiate-distributions",
    "title": "Statistics",
    "section": "Univaiate Distributions",
    "text": "Univaiate Distributions\n\nNormal Distribution\nA random variable \\(X\\) is said to be normally distrbuted if it has a probability density function as follows\n\\[f_X(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-{\\frac{1}{2}}(\\frac{x-\\mu}{\\sigma})^2}\\]\nIt is a continous probability distribution\n\\(\\mu\\) and \\(\\sigma\\) are the mean and variance of the distribution respectively\nThe case where \\(\\mu =0\\) and \\(\\sigma = 1\\) is called standard normal distribution and its PDF is given by \\[  f_X(x) =\\frac{1}{\\sqrt{2\\pi}}e^{\\frac{-x^2}{2}}\\]\n\nimport numpy as np\nimport math \nimport matplotlib.pyplot as plt\nimport scipy.stats as st\nfrom mpl_toolkits import mplot3d\n\n\ndef plotNormalPDF_CDF_CHF(mu ,sigma):\n    i = complex(0,1)\n    chf = lambda u : np.exp(i*mu*u -(sigma**2)*u*u/2)\n    pdf = lambda x : st.norm.pdf(x,mu,sigma)\n    cdf = lambda x : st.norm.cdf(x,mu,sigma)\n    \n    x = np.linspace(5,15,100)\n    u = np.linspace(0,5,250)\n    print(type(pdf))\n    # figure 1 ,PDF\n    plt.figure(1)\n    plt.plot(x,pdf(x))\n    plt.grid()\n    plt.xlabel('x')\n    plt.ylabel('PDF')\n  \n    # figure 2 ,CDF\n    plt.figure(2)\n    plt.plot(x,cdf(x))\n    plt.grid()\n    plt.xlabel('x')\n    plt.ylabel('CDF')\n  \n    #  figure 3 ,CHF\n  \n    plt.figure(3)\n    ax = plt.axes(projection = '3d')\n    chfV = chf(u)\n  \n    x = np.real(chfV)\n    y = np.imag(chfV)\n    ax.plot3D(u,x,y,'red')\n    ax.view_init(30 ,-120)\n    \nplotNormalPDF_CDF_CHF(10,1)\n\n<class 'function'>\n\n\n\n\n\n\n\n\n\n\n\n\n\nLog Normal Distibution\nA random Variable \\(X\\) is said to have log normal distibution if \\(Y = \\ln{X}\\) and \\(Y\\) is normally distributed.\nThe PDF of log normal distribution is given by\n\\[f_X(x) = \\frac{1}{x\\sigma\\sqrt{2\\pi}}e^{(-\\frac{(\\ln{x} -\\mu)^2}{2{\\sigma}^2})}\\] where \\(\\mu\\) and \\(\\sigma\\) are the mean and variance of \\(Y(\\ln X)\\) respectively.\nHence the mean \\(\\mu^*\\) and variance \\(\\sigma^*\\) of X are as follows\n\\[\\mu^* = e^{\\mu + \\frac{1}{2}\\sigma^2}\\] \\[\\sigma^* = e^{2\\mu + 2\\sigma^2} - e^{2\\mu +\\sigma^2}\\] Important thing to note here is that \\(x\\) can take values in \\((0,\\infty)\\) only."
  },
  {
    "objectID": "docu/SEA/Q_F/statistics.html#multivariate-distributions",
    "href": "docu/SEA/Q_F/statistics.html#multivariate-distributions",
    "title": "Statistics",
    "section": "Multivariate Distributions",
    "text": "Multivariate Distributions\n\nCorrelation\nThe correlation coefficient between two random variables \\(X\\) and \\(Y\\) is defined as \\[ \\rho_{x,y} = \\frac{Cov(X,Y)}{\\sqrt{Var(X)Var(Y)}} = \\frac{E[(X-\\mu_x)(Y-\\mu_y)]}{\\sqrt{E(X-\\mu_x)^2E(Y-\\mu_y)^2}}\\]\nThe sample correlation is given by \\[ \\hat\\rho_{x,y} = \\frac{\\sum_{t=1}^{T}(x_t - \\bar{x})(y_t - \\bar{y})}{\\sqrt{\\sum_{t=1}^T(x_t - \\bar{x})\\sum_{t=1}^T(y_t - \\bar{y})}}\\]"
  },
  {
    "objectID": "docu/SEA/data_analysis.html",
    "href": "docu/SEA/data_analysis.html",
    "title": "Data Analysis for Python",
    "section": "",
    "text": "List of important libraries and tools that are mainly used for data analysis in python * Numpy: Numerical Python has great array processing capabilities. Mostly used to pass data to algorithims from datasets/libraries. It gives the ability to perform linear algebra operations ,Fourier transforms with ease.\n\nPandas: Mostly used to manipulate and create new data structures.\nMatplotlib: Used for plots and other two dimensional data visualizations\nJupyter: Commonly used for testing , running iterations, debugging before sending off the code to production. Jupyter notebook supports R , python and julia programming languages as well as markdown for documenting the files\nSciPy: Scientific computing library. Provides functionality to integrate , optimise , signal processing,etc…\nScikit-learn: The library has machine learning models which can be used out of the box. Has all the standard machine learning models.\n\nAll of the above tools and libraries are very well documented and navigating through them is relatively easy.\n\n#Importing Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels as sm"
  },
  {
    "objectID": "docu/SEA/data_analysis.html#python",
    "href": "docu/SEA/data_analysis.html#python",
    "title": "Data Analysis for Python",
    "section": "Python",
    "text": "Python\n\nIpython Shortcuts\n\n%a: Commonly known as magic functions. Specific to Ipython kernel\n%run a.py: runs the python file a.py located in the same working directory\n%quickref: gives quick reference\nhelp - help function for Ipython\na?: gives general information about the object a\n%load a.py: Import a.py script into the code cell\n%paste: Will paste contents in the keyboard and execute the as a single block\n%timeit b:Gives the execution time of python statement b.Can be run muliple times giving the average time over all iterations as output.\n%debug: Various positional arguments available to debug a python statement.\n%pwd: Gives current path as output\n%xdel variable : Deletes teh varaible and attempt to clear all references to the object in python\n\n\n\nPython\n\n#checks the current versiom of kernel being used\nimport sys\nprint(sys.executable)\nprint(sys.version)\nprint(sys.version_info)\n\n/opt/homebrew/opt/python@3.10/bin/python3.10\n3.10.8 (main, Oct 13 2022, 09:48:40) [Clang 14.0.0 (clang-1400.0.29.102)]\nsys.version_info(major=3, minor=10, micro=8, releaselevel='final', serial=0)\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()"
  },
  {
    "objectID": "docu/Resources/Research_papers.html#compuational-finance",
    "href": "docu/Resources/Research_papers.html#compuational-finance",
    "title": "Reseach Papers",
    "section": "Compuational finance",
    "text": "Compuational finance"
  },
  {
    "objectID": "docu/Resources/Research_papers.html#decentralised-finance-anb-cryptography-papers",
    "href": "docu/Resources/Research_papers.html#decentralised-finance-anb-cryptography-papers",
    "title": "Reseach Papers",
    "section": "Decentralised finance anb Cryptography papers",
    "text": "Decentralised finance anb Cryptography papers"
  },
  {
    "objectID": "docu/Resources/Research_papers.html#abstract-mathematics",
    "href": "docu/Resources/Research_papers.html#abstract-mathematics",
    "title": "Reseach Papers",
    "section": "Abstract Mathematics",
    "text": "Abstract Mathematics"
  },
  {
    "objectID": "docu/Resources/Research_papers.html#decentralised-finance-and-cryptography-papers",
    "href": "docu/Resources/Research_papers.html#decentralised-finance-and-cryptography-papers",
    "title": "Reseach Papers",
    "section": "Decentralised finance and Cryptography papers",
    "text": "Decentralised finance and Cryptography papers"
  },
  {
    "objectID": "docu/SEA/StochC.html#preliminaries",
    "href": "docu/SEA/StochC.html#preliminaries",
    "title": "Stochastic Calculus",
    "section": "Preliminaries",
    "text": "Preliminaries\n\nDefinition 1 (\\sigma algebra) : Let \\Omega be a nonempty set , and let \\mathcal{F} be a set of collections of subsets of \\Omega. We say that \\mathcal{F} is a \\sigma algebra provided that\n\nThe empty set \\emptyset belongs to \\mathcal{F}\nA and A^{c} belong to \\mathcal{F} whenever A \\in \\mathcal{F}\nwhenever A_1 ,A_2 ,A_3 ..... \\in \\mathcal{F} then \\bigcup_{i=1}^\\infty A_{i} \\in \\mathcal{F}\n\n\n \n\nDefinition 2 (Probability measure) : Let \\Omega be a nonempty set , and let \\mathbb{F} be \\sigma algebra of subsets of \\Omega. A probability measure \\mathbb{P} is a function that, to every set A \\in \\mathcal{F} , assigns a number in [0,1] called the probability of A written as \\mathbb{P}(A) .We require\n\n\\mathbb{P}(\\Omega) = 1 and\n(Countable Additivity) Whenever A_1,A_2,A_3.... is a sequence of disjoint sets in \\mathcal{F} , then \\mathbb{P}(\\bigcup_{n=1}^\\infty A_n) = \\sum_{n=1}^{\\infty} \\mathbb{P}(A_n) \n\n The Triple (\\Omega, \\mathcal{F},\\mathbb{}P) is called probability measure\n\n From the above it follows that for finitely many disjoint sets A_1, A_2,A_3....A_n \\mathbb{P}(\\bigcup_{n=1}^N) = \\sum_{n=1}^N \\mathbb{P}(A_n)\nand \\mathbb{P}(A^c) = 1 - \\mathbb{P}(A)\n\nExample 1 (Uniform(Lebesgue) measure on [0,1])  \\Omega = [0,1] \\mathbb{P}[a,b] = b-a ,0 \\leq a \\leq b \\leq1  single points have zero probability and  (a,b) can be written as  \\bigcup_{n=1}^\\infty[a+\\frac{1}{n} , b -\\frac{1}{n}]\n\n  The \\sigma-algebra beginning with closed intervals and adding everything else necessary in order to have a \\sigma- algebra is called a Borel \\sigma-algebra and denoted by \\mathcal{B}[0,1]. Borel \\sigma-algebras are \\sigma-algebra generated by open sets and equivalently closed sets over any topological space.\n\nDefinition 3 let (\\Omega,\\mathcal{F},\\mathbb{P}) be a probability space. If a set A \\in \\mathcal{F} satisfies \\mathbb{P}(A) = 1, we say the event A occurs almost surely\n\n\nExample 2 Let \\mathbb{P} be the uniform measure as defined in example 1. Define X(\\omega) = \\omega and Y(\\omega) = 1 - \\omega for all \\omega \\in [0,1] , then the distribution measure of X is uniform \\mu_{X}[a,b] = \\mathbb{P}\\{\\omega;a\\leq X(w)\\leq b\\} = \\mathbb{P}[a,b] = b-a, 0\\leq a \\leq b \\leq 1 by definition of \\mathbb{P}.  Its easy to see to see that X and Y have the same distribution. But under the probability measure\\mathbb{\\widetilde{P}} on [0,1] defined by \\mathbb{\\widetilde{P}[a,b]} = \\int_a^b 2\\omega \\, d\\omega = b^2-a^2  , 0 \\leq a\\leq b \\leq1  X and Y have different distributions.\n\n\nDefinition 4 (cumulative distribution function and density function)  F(x) = \\mathbb{P}\\{X \\leq x\\} , x \\in \\mathbb{R} \\mu_X[a,b] = \\mathbb{P}\\{a \\leq X \\leq b \\} = \\int_a^b f(x) \\, dx , -\\infty < a \\leq b < \\infty f(x) is called the density funtion and F(x) is called the cummulative distribution function.\n\n\nExample 3 (Standard normal random variable) Let \\phi(x)  = \\frac {a}{\\sqrt{2\\pi}}e^{\\frac{-x^2}{2}} be the standard normal density and definiing the cummulative normal distribution function as N(x) = \\int_{-\\infty}^x \\phi(\\xi)\\,d\\xi The function N(x) is strictly increasing function which is surjective onto (0,1) from \\mathbb{R}, so it has a strictly increasing inverse function N^{-1}(y),y \\in (0,1). Let Y be a uniformly distributed random variable defined on some probability space (\\Omega,\\mathcal{F},\\mathbb{P}) and set X = N^{-1}(Y) then\n\\begin{align*}\n\n\\mu_X[a,b] &= \\mathbb{P}\\{\\omega \\in \\Omega ; a \\leq X(\\omega) \\leq b\\} \\\\\n\n          &= \\mathbb{P}\\{\\omega \\in \\Omega ; a \\leq N^{-1}(Y(\\omega)) \\leq b\\}\\\\\n            \n          &= \\mathbb{P}\\{\\omega \\in \\Omega ; N(a) \\leq Y(\\omega) \\leq N(b) \\} \\\\\n        \n          &= N(b) - N(a) \\\\\n          &= \\int_a^b \\phi(x) \\, dx\n\n\\end{align*}\nAny random variable that has this distribution regardless of the probability space is called standard normal distribution. Thing to note the use of uniformly distributed random variable for generating a standard random variable is called probability integral transform and this is commonly used in Monte Carlo simulation"
  }
]